---
name: Investigating Offline Reinforcement Learning
tools: [Reinforcement Learning, Research, TensorFlow, Python]
image: https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExZDBuZHN0dmJpamJndWQ4a2cwY3piYzZzZmt2dm83MzZxdXI5aG1hYiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ekygkIYiP1ZJs6UjBR/giphy.gif
description: Taught a half cheetah how to run using offline RL
---

# Investigating Offline Reinforcement Learning


Two friends and I trained an offline RL model using [D4RL](https://sites.google.com/view/d4rl/home) and the Stationary Distribution Correction algorithm from [OptiDICE](https://arxiv.org/pdf/2106.10783.pdf).
								
We tested and experimented the stability and accuracy of the model in [MuJoCo](https://mujoco.org/) environment with agent cheetah and maze-2d. 

<p class="text-center">
<iframe src="https://drive.google.com/file/d/100PSuSe0Ok4Op2Zw2vGqkQx5Ps3iCmH8/preview" width="70%" height="500" allow="autoplay"></iframe>
</p>